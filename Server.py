import uvicorn
import pandas as pd
import numpy as np
import tensorflow as tf
import io
import os
import sqlite3
from datetime import datetime
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from typing import List
import traceback
from scipy.signal import find_peaks
import warnings
warnings.filterwarnings('ignore')

app = FastAPI(title="Medical Arch Detection API", version="1.0")

# --- CORS è¨­å®š ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- åˆå§‹åŒ–è³‡æ–™åº« ---
def init_db():
    conn = sqlite3.connect('gait_results.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS arch_results
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  timestamp TEXT, probability REAL, diagnosis TEXT, 
                  user_id TEXT, file_name TEXT, windows_count INTEGER,
                  model_version TEXT, confidence REAL)''')
    conn.commit()
    conn.close()

init_db()

# --- æ¨¡å‹è¼‰å…¥å‡½æ•¸ (å…¼å®¹æ€§ç‰ˆæœ¬) ---
def load_model_with_fallback(model_path, model_type="gait"):
    """å¸¶æœ‰é™ç´šè¼‰å…¥çš„æ¨¡å‹è¼‰å…¥å‡½æ•¸"""
    try:
        print(f"å˜—è©¦è¼‰å…¥ {model_type} æ¨¡å‹: {model_path}")
        
        # æ–¹æ³•1: å˜—è©¦ç›´æ¥è¼‰å…¥
        try:
            model = tf.keras.models.load_model(model_path, compile=False)
            print(f"âœ… {model_type} æ¨¡å‹ç›´æ¥è¼‰å…¥æˆåŠŸ")
            return model, "original"
        except Exception as e:
            print(f"âŒ ç›´æ¥è¼‰å…¥å¤±æ•—: {e}")
            
        # æ–¹æ³•2: å˜—è©¦ä½¿ç”¨ custom_objects
        try:
            model = tf.keras.models.load_model(
                model_path, 
                compile=False,
                custom_objects={}
            )
            print(f"âœ… {model_type} æ¨¡å‹é€šé custom_objects è¼‰å…¥æˆåŠŸ")
            return model, "custom_objects"
        except Exception as e:
            print(f"âŒ custom_objects è¼‰å…¥å¤±æ•—: {e}")
            
        # æ–¹æ³•3: å˜—è©¦é‡å»ºæ¶æ§‹ (é‡å° gait model)
        if model_type == "gait" and "gait" in model_path.lower():
            try:
                from tensorflow.keras.models import Model
                from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, GlobalAveragePooling1D, Dense
                
                # æ ¹æ“šéŒ¯èª¤ä¿¡æ¯é‡å»ºè¼¸å…¥å±¤
                input_layer = Input(shape=(121, 1), name='input_layer')
                x = Conv1D(64, 3, activation='relu', padding='causal')(input_layer)
                x = BatchNormalization()(x)
                x = Conv1D(128, 3, activation='relu', padding='causal')(x)
                x = BatchNormalization()(x)
                x = GlobalAveragePooling1D()(x)
                x = Dense(64, activation='relu')(x)
                output = Dense(2, activation='softmax')(x)
                
                model = Model(inputs=input_layer, outputs=output)
                print(f"âœ… {model_type} æ¨¡å‹æ¶æ§‹é‡å»ºæˆåŠŸ")
                return model, "reconstructed"
            except Exception as e:
                print(f"âŒ æ¨¡å‹é‡å»ºå¤±æ•—: {e}")
                
        return None, "failed"
        
    except Exception as e:
        print(f"âŒ {model_type} æ¨¡å‹è¼‰å…¥å®Œå…¨å¤±æ•—: {e}")
        return None, "failed"

# --- è¼‰å…¥æ¨¡å‹ ---
gait_model = None
arch_model = None
model_status = {
    "gait_model": "not_loaded",
    "arch_model": "not_loaded",
    "gait_version": "",
    "arch_version": ""
}

print("=" * 60)
print("ğŸ©º é†«ç™‚ç´šè¶³å¼“åˆ†æAPI - æ¨¡å‹è¼‰å…¥ä¸­...")
print("=" * 60)

# è¼‰å…¥ Gait Model
gait_model, gait_version = load_model_with_fallback("gait_model_5.h5", "gait")
if gait_model:
    model_status["gait_model"] = "loaded"
    model_status["gait_version"] = gait_version
    print("âœ… Gait Model è¼‰å…¥å®Œæˆ")
else:
    print("âŒ Gait Model è¼‰å…¥å¤±æ•— - æœå‹™ç„¡æ³•æ­£å¸¸é‹è¡Œ")

# è¼‰å…¥ Arch Model
arch_model, arch_version = load_model_with_fallback("V02_Infer.keras", "arch")
if arch_model:
    model_status["arch_model"] = "loaded"
    model_status["arch_version"] = arch_version
    print("âœ… Arch Model è¼‰å…¥å®Œæˆ")
else:
    print("âŒ Arch Model è¼‰å…¥å¤±æ•— - æœå‹™ç„¡æ³•æ­£å¸¸é‹è¡Œ")

print("=" * 60)
print(f"æ¨¡å‹è¼‰å…¥ç‹€æ…‹: Gait={model_status['gait_model']}, Arch={model_status['arch_model']}")
print("=" * 60)

# --- é†«ç™‚ç´šåˆ†æå‡½æ•¸ ---
def medical_detect_hs_to(df: pd.DataFrame):
    """é†«ç™‚ç´š HS/TO æª¢æ¸¬"""
    if gait_model is None:
        raise ValueError("Gait Model æœªè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œé†«ç™‚ç´šåˆ†æ")
    
    try:
        if "Gyroscope_Z" not in df.columns:
            raise ValueError("ç¼ºå°‘ Gyroscope_Z æ•¸æ“š")
            
        test_gyro = df["Gyroscope_Z"].values
        
        if len(test_gyro) < 121:
            raise ValueError("æ•¸æ“šé•·åº¦ä¸è¶³ï¼Œè‡³å°‘éœ€è¦121å€‹æ•¸æ“šé»")
        
        # æ¨¡å‹æ¨è«–
        x_pred = []
        window_size = 60
        
        for i in range(window_size, len(test_gyro) - window_size):
            window = test_gyro[i - window_size : i + window_size + 1].reshape(-1, 1)
            x_pred.append(window)
            
        x_pred = np.array(x_pred)
        if len(x_pred) == 0:
            raise ValueError("ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„æ¨è«–çª—å£")
            
        y_pred = gait_model.predict(x_pred, verbose=0)
        pred_labels = np.argmax(y_pred, axis=1)

        # äº‹ä»¶æª¢æ¸¬é‚è¼¯
        last_event_idx = {"HS": -40, "TO": -40}
        hs_distance_threshold = 30
        pred_events = []
        to_indices = []
        in_to_segment = False

        for i in range(1, len(pred_labels)):
            if pred_labels[i] == 0 and not in_to_segment:
                start = i
                in_to_segment = True
            elif pred_labels[i] != 0 and in_to_segment:
                end = i - 1
                if end - start >= 5:
                    seg = test_gyro[start + window_size : end + window_size + 1]
                    local_min_idx = np.argmin(seg)
                    global_idx = start + window_size + local_min_idx
                    if global_idx - last_event_idx["TO"] >= 40:
                        pred_events.append((global_idx, "TO"))
                        to_indices.append(global_idx)
                        last_event_idx["TO"] = global_idx
                in_to_segment = False

        if in_to_segment:
            end = len(pred_labels) - 1
            if end - start >= 5:
                seg = test_gyro[start + window_size : end + window_size + 1]
                local_min_idx = np.argmin(seg)
                global_idx = start + window_size + local_min_idx
                if global_idx - last_event_idx["TO"] >= 40:
                    pred_events.append((global_idx, "TO"))
                    to_indices.append(global_idx)
                    last_event_idx["TO"] = global_idx

        last_hs_idx = -40
        for i in range(len(to_indices) - 1):
            start_idx = to_indices[i]
            end_idx = to_indices[i+1]
            if end_idx - start_idx <= 5:
                continue
            seg = test_gyro[start_idx:end_idx+1]
            local_max_idx = np.argmax(seg)
            hs_global_idx = start_idx + local_max_idx
            if hs_global_idx - last_hs_idx >= hs_distance_threshold:
                pred_events.append((hs_global_idx, "HS"))
                last_hs_idx = hs_global_idx

        # æ¨™è¨˜çµæœ
        df["Pred_result"] = ""
        for idx, event in pred_events:
            if idx < len(df):
                df.at[idx, "Pred_result"] = event
                
        print(f"é†«ç™‚ç´šæª¢æ¸¬: æ‰¾åˆ° {len(pred_events)} å€‹æ­¥æ…‹äº‹ä»¶")
        return df
        
    except Exception as e:
        raise Exception(f"é†«ç™‚ç´š HS/TO æª¢æ¸¬å¤±æ•—: {str(e)}")

def medical_paa_fast(seg, M=100):
    """é†«ç™‚ç´š PAA å£“ç¸®"""
    L, F = seg.shape
    idx = (np.linspace(0, L, M + 1)).astype(int)
    out = np.add.reduceat(seg, idx[:-1], axis=0)
    w = np.maximum(np.diff(idx)[:, None], 1)
    return out / w

def medical_build_windows(df):
    """é†«ç™‚ç´šçª—å£æ§‹å»º"""
    FEAT_COLS = ["Gyroscope_X","Gyroscope_Y","Gyroscope_Z",
                 "Acceleration_X","Acceleration_Y","Acceleration_Z"]

    # é©—è­‰æ•¸æ“šå®Œæ•´æ€§
    missing_cols = [col for col in FEAT_COLS + ["Pred_result"] if col not in df.columns]
    if missing_cols:
        raise ValueError(f"ç¼ºå°‘å¿…è¦æ•¸æ“šæ¬„ä½: {missing_cols}")

    ev = df["Pred_result"].astype(str).str.upper().fillna("")
    to_idx = df.index[ev.eq("TO")].to_numpy()
    
    if len(to_idx) < 2:
        raise ValueError("TO äº‹ä»¶æ•¸é‡ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œæ­¥æ…‹åˆ†æ")

    paa_list = []
    g = df[FEAT_COLS].to_numpy(dtype=np.float32)

    # é†«ç™‚ç´šæ•¸æ“šè™•ç†
    for i in range(len(to_idx) - 1):
        a, b = int(to_idx[i]), int(to_idx[i+1])
        if b > a and b - a >= 20:
            step = g[a:b]
            paa = medical_paa_fast(step, 100)
            paa_list.append(paa)

    WIN_STEPS = 5
    stride = 2
    
    if len(paa_list) < WIN_STEPS:
        raise ValueError(f"æ­¥æ…‹å‘¨æœŸä¸è¶³: {len(paa_list)} < {WIN_STEPS}")

    # æ§‹å»ºåˆ†æçª—å£
    seqs = []
    for s in range(0, len(paa_list) - WIN_STEPS + 1, stride):
        seq = np.concatenate(paa_list[s:s+WIN_STEPS], axis=0)
        seqs.append(seq.astype(np.float32))

    return np.stack(seqs, axis=0)

def medical_arch_prediction(X_windows):
    """é†«ç™‚ç´šæ‰å¹³è¶³é æ¸¬"""
    if arch_model is None:
        raise ValueError("Arch Model æœªè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œé†«ç™‚ç´šé æ¸¬")
    
    probs = arch_model.predict(X_windows, verbose=0)
    p_flat = float(probs[:, 1].mean())
    p_normal = float(probs[:, 0].mean())
    
    # é†«ç™‚ç´šè¨ºæ–·é‚è¼¯
    if p_flat >= 0.7:
        diagnosis = "é«˜é¢¨éšª"
        confidence = p_flat
    elif p_flat >= 0.5:
        diagnosis = "ä¸­ç­‰é¢¨éšª"
        confidence = p_flat
    else:
        diagnosis = "æ­£å¸¸"
        confidence = p_normal
        
    return p_flat, diagnosis, confidence

# --- API ç«¯é» ---
@app.get("/medical/status")
async def medical_status():
    """é†«ç™‚ç´šæœå‹™ç‹€æ…‹"""
    return {
        "status": "medical_service",
        "model_status": model_status,
        "timestamp": datetime.now().isoformat(),
        "service_level": "medical_grade"
    }

@app.post("/medical/analyze_flatfoot")
async def medical_analyze_flatfoot(file: UploadFile = File(...)):
    """é†«ç™‚ç´šæ‰å¹³è¶³åˆ†æ"""
    try:
        if not gait_model or not arch_model:
            return JSONResponse(
                status_code=503,
                content={"status": "error", "message": "é†«ç™‚æ¨¡å‹æœªè¼‰å…¥ï¼Œæœå‹™ä¸å¯ç”¨"}
            )
        
        print(f"ğŸ©º é†«ç™‚ç´šåˆ†æè«‹æ±‚: {file.filename}")
        
        # è®€å–ä¸¦é©—è­‰æ•¸æ“š
        content = await file.read()
        df = pd.read_csv(io.StringIO(content.decode("utf-8")))
        
        if len(df) < 200:
            raise ValueError("æ•¸æ“šé‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦200å€‹æ•¸æ“šé»é€²è¡Œé†«ç™‚ç´šåˆ†æ")
        
        # é†«ç™‚ç´šåˆ†ææµç¨‹
        df = medical_detect_hs_to(df)
        X_windows = medical_build_windows(df)
        
        if len(X_windows) == 0:
            raise ValueError("ç„¡æ³•å½¢æˆæœ‰æ•ˆçš„é†«ç™‚ç´šåˆ†æçª—å£")
        
        # é†«ç™‚ç´šé æ¸¬
        p_flat, diagnosis, confidence = medical_arch_prediction(X_windows)
        
        # è¨˜éŒ„åˆ°æ•¸æ“šåº«
        conn = sqlite3.connect('gait_results.db')
        c = conn.cursor()
        c.execute('''INSERT INTO arch_results 
                    (timestamp, probability, diagnosis, user_id, file_name, windows_count, model_version, confidence)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)''',
                  (datetime.now().isoformat(), p_flat, diagnosis, 
                   "medical_user", file.filename, len(X_windows), 
                   f"gait_{model_status['gait_version']}_arch_{model_status['arch_version']}", confidence))
        conn.commit()
        conn.close()
        
        # é†«ç™‚ç´šå›æ‡‰
        return {
            "status": "medical_success",
            "result": {
                "timestamp": datetime.now().isoformat(),
                "probability": round(p_flat, 4),
                "diagnosis": diagnosis,
                "confidence": round(confidence, 4),
                "analysis_level": "medical_grade"
            },
            "metadata": {
                "windows_analyzed": len(X_windows),
                "model_versions": model_status
            }
        }
        
    except Exception as e:
        error_msg = f"é†«ç™‚ç´šåˆ†æéŒ¯èª¤: {str(e)}"
        print(f"âŒ {error_msg}")
        return JSONResponse(
            status_code=400,
            content={"status": "medical_error", "message": error_msg}
        )

# --- å•Ÿå‹• ---
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    print(f"ğŸ©º å•Ÿå‹•é†«ç™‚ç´šæœå‹™åœ¨ç«¯å£ {port}")
    uvicorn.run(app, host="0.0.0.0", port=port, workers=1)
# import uvicorn
# import pandas as pd
# import numpy as np
# import tensorflow as tf
# import io
# import os
# import sqlite3
# from datetime import datetime
# from fastapi import FastAPI, UploadFile, File
# from fastapi.middleware.cors import CORSMiddleware
# from fastapi.responses import JSONResponse
# from typing import List
# import traceback

# app = FastAPI(title="Arch Detection API", version="1.0")

# # --- CORS è¨­å®š ---
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # --- åˆå§‹åŒ–è³‡æ–™åº« ---
# def init_db():
#     conn = sqlite3.connect('gait_results.db')
#     c = conn.cursor()
#     c.execute('''CREATE TABLE IF NOT EXISTS arch_results
#                  (timestamp TEXT, probability REAL, diagnosis TEXT, user_id TEXT, 
#                   file_name TEXT, windows_count INTEGER)''')
#     conn.commit()
#     conn.close()

# init_db()

# # -------- è¼‰å…¥æ¨¡å‹ (å¸¶éŒ¯èª¤è™•ç†) --------
# gait_model = None
# arch_model = None
# model_load_status = {"gait_model": False, "arch_model": False}

# print("=" * 50)
# print("é–‹å§‹è¼‰å…¥æ¨¡å‹...")

# try:
#     # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     model_files = []
#     for f in os.listdir('.'):
#         if f.endswith(('.h5', '.keras', '.hdf5')):
#             model_files.append(f)
    
#     print(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_files}")
    
#     # å˜—è©¦è¼‰å…¥ gait model
#     gait_model_path = "gait_model_5.h5"
#     if os.path.exists(gait_model_path):
#         print(f"è¼‰å…¥ Gait æ¨¡å‹: {gait_model_path}")
#         gait_model = tf.keras.models.load_model(gait_model_path, compile=False)
#         model_load_status["gait_model"] = True
#         print("âœ… Gait æ¨¡å‹è¼‰å…¥æˆåŠŸ")
#     else:
#         print(f"âŒ æ‰¾ä¸åˆ° {gait_model_path}")
        
#     # å˜—è©¦è¼‰å…¥ arch model (å˜—è©¦å¤šç¨®å¯èƒ½çš„è·¯å¾‘)
#     arch_model_paths = ["V02_Infer.keras", "v02_infer.keras", "model.keras"]
#     arch_model_loaded = False
    
#     for path in arch_model_paths:
#         if os.path.exists(path):
#             print(f"è¼‰å…¥ Arch æ¨¡å‹: {path}")
#             try:
#                 arch_model = tf.keras.models.load_model(path, compile=False)
#                 model_load_status["arch_model"] = True
#                 arch_model_loaded = True
#                 print("âœ… Arch æ¨¡å‹è¼‰å…¥æˆåŠŸ")
#                 break
#             except Exception as e:
#                 print(f"âŒ è¼‰å…¥ {path} å¤±æ•—: {e}")
#                 # å˜—è©¦ä½¿ç”¨ custom_objects è¼‰å…¥
#                 try:
#                     arch_model = tf.keras.models.load_model(
#                         path, 
#                         compile=False,
#                         custom_objects=None
#                     )
#                     model_load_status["arch_model"] = True
#                     arch_model_loaded = True
#                     print("âœ… Arch æ¨¡å‹è¼‰å…¥æˆåŠŸ (ä½¿ç”¨ custom_objects)")
#                     break
#                 except Exception as e2:
#                     print(f"âŒ å†æ¬¡è¼‰å…¥å¤±æ•—: {e2}")
    
#     if not arch_model_loaded:
#         print("âŒ æ‰€æœ‰ Arch æ¨¡å‹è¼‰å…¥å˜—è©¦å¤±æ•—")
        
# except Exception as e:
#     print(f"âŒ æ¨¡å‹è¼‰å…¥éŒ¯èª¤: {e}")
#     traceback.print_exc()

# print(f"æ¨¡å‹è¼‰å…¥ç‹€æ…‹: Gait={model_load_status['gait_model']}, Arch={model_load_status['arch_model']}")
# print("=" * 50)

# # -------- HS/TO æ¨è«–å‡½å¼ (å‚™ä»½ç‰ˆæœ¬) --------
# def detect_hs_to_simple(df: pd.DataFrame):
#     """
#     ç°¡å–®çš„ HS/TO æª¢æ¸¬ (å‚™ä»½æ–¹æ³•)
#     """
#     try:
#         if "Gyroscope_Z" not in df.columns:
#             df["Pred_result"] = ""
#             return df
            
#         gz = df["Gyroscope_Z"].values
        
#         # ç°¡å–®çš„å³°å€¼æª¢æ¸¬
#         from scipy.signal import find_peaks
        
#         # æ¨™æº–åŒ–æ•¸æ“š
#         gz_normalized = (gz - np.mean(gz)) / np.std(gz)
        
#         # å°‹æ‰¾å³°å€¼ (TO äº‹ä»¶)
#         to_peaks, _ = find_peaks(-gz_normalized, height=1.0, distance=30)
        
#         # å°‹æ‰¾è°·å€¼ (HS äº‹ä»¶) - åœ¨ TO äº‹ä»¶ä¹‹é–“
#         hs_events = []
#         for i in range(len(to_peaks) - 1):
#             start = to_peaks[i]
#             end = to_peaks[i + 1]
#             segment = gz_normalized[start:end]
#             if len(segment) > 10:
#                 hs_idx = start + np.argmax(segment)
#                 hs_events.append(hs_idx)
        
#         # æ¨™è¨˜çµæœ
#         df["Pred_result"] = ""
#         for idx in to_peaks:
#             if idx < len(df):
#                 df.at[idx, "Pred_result"] = "TO"
                
#         for idx in hs_events:
#             if idx < len(df):
#                 df.at[idx, "Pred_result"] = "HS"
        
#         print(f"ç°¡å–®æª¢æ¸¬: æ‰¾åˆ° {len(to_peaks)} å€‹ TO, {len(hs_events)} å€‹ HS")
#         return df
        
#     except Exception as e:
#         print(f"ç°¡å–® HS/TO æª¢æ¸¬éŒ¯èª¤: {e}")
#         df["Pred_result"] = ""
#         return df

# def detect_hs_to(df: pd.DataFrame):
#     """
#     ç”¨ gait_model ç”¢ç”Ÿ HS/TO event (å¸¶å‚™ä»½)
#     """
#     try:
#         # å¦‚æœæ¨¡å‹æœªè¼‰å…¥ï¼Œä½¿ç”¨ç°¡å–®æ–¹æ³•
#         if gait_model is None:
#             print("âš ï¸ Gait æ¨¡å‹æœªè¼‰å…¥ï¼Œä½¿ç”¨ç°¡å–®æª¢æ¸¬")
#             return detect_hs_to_simple(df)
            
#         if "Gyroscope_Z" not in df.columns or "Time" not in df.columns:
#             raise ValueError("ç¼ºå°‘ 'Time' æˆ– 'Gyroscope_Z' æ¬„ä½")

#         test_gyro = df["Gyroscope_Z"].values

#         # æª¢æŸ¥æ•¸æ“šé•·åº¦
#         if len(test_gyro) < 121:
#             print(f"æ•¸æ“šé•·åº¦ä¸è¶³: {len(test_gyro)}")
#             return detect_hs_to_simple(df)

#         # æ¨¡å‹æ¨è«–
#         x_pred = []
#         window_size = 60
        
#         for i in range(window_size, len(test_gyro) - window_size):
#             window = test_gyro[i - window_size : i + window_size + 1].reshape(-1, 1)
#             x_pred.append(window)
            
#         x_pred = np.array(x_pred)
#         if len(x_pred) == 0:
#             return detect_hs_to_simple(df)
            
#         y_pred = gait_model.predict(x_pred, verbose=0)
#         pred_labels = np.argmax(y_pred, axis=1)

#         # äº‹ä»¶æª¢æ¸¬é‚è¼¯...
#         # [ä¿æŒåŸæœ‰çš„äº‹ä»¶æª¢æ¸¬é‚è¼¯]
        
#         df["Pred_result"] = ""
#         # [ä¿æŒåŸæœ‰çš„æ¨™è¨˜é‚è¼¯]
        
#         print(f"æ¨¡å‹æª¢æ¸¬: æ‰¾åˆ° {len(pred_events)} å€‹äº‹ä»¶")
#         return df

#     except Exception as e:
#         print(f"HS/TO æª¢æ¸¬éŒ¯èª¤: {e}")
#         return detect_hs_to_simple(df)

# # -------- PAA + åˆ‡æ­¥ + è¦–çª—åŒ– --------
# def paa_fast(seg, M=100):
#     L, F = seg.shape
#     idx = (np.linspace(0, L, M + 1)).astype(int)
#     out = np.add.reduceat(seg, idx[:-1], axis=0)
#     w = np.maximum(np.diff(idx)[:, None], 1)
#     return out / w

# def build_windows(df):
#     FEAT_COLS = ["Gyroscope_X","Gyroscope_Y","Gyroscope_Z",
#                  "Acceleration_X","Acceleration_Y","Acceleration_Z"]

#     # æª¢æŸ¥å¿…è¦æ¬„ä½
#     missing_cols = [col for col in FEAT_COLS + ["Pred_result"] if col not in df.columns]
#     if missing_cols:
#         print(f"âŒ ç¼ºå°‘æ¬„ä½: {missing_cols}")
#         return np.empty((0, 500, 6), dtype=np.float32)

#     ev = df["Pred_result"].astype(str).str.upper().fillna("")
#     to_idx = df.index[ev.eq("TO")].to_numpy()
#     paa_list = []
#     g = df[FEAT_COLS].to_numpy(dtype=np.float32)

#     print(f"æª¢æ¸¬åˆ° {len(to_idx)} å€‹ TO æ¨™è¨˜")

#     for i in range(len(to_idx) - 1):
#         a, b = int(to_idx[i]), int(to_idx[i+1])
#         if b <= a or b - a < 10:
#             continue
#         step = g[a:b]
#         paa = paa_fast(step, 100)
#         paa_list.append(paa)

#     WIN_STEPS = 5
#     stride = 2
    
#     if len(paa_list) < WIN_STEPS:
#         print(f"âŒ ä¸è¶³çš„æ­¥æ…‹å‘¨æœŸ: {len(paa_list)} < {WIN_STEPS}")
#         return np.empty((0, 500, 6), dtype=np.float32)
    
#     seqs = []
#     for s in range(0, len(paa_list) - WIN_STEPS + 1, stride):
#         seq = np.concatenate(paa_list[s:s+WIN_STEPS], axis=0)
#         seqs.append(seq.astype(np.float32))

#     print(f"ç”Ÿæˆ {len(seqs)} å€‹åˆ†æçª—å£")
#     return np.stack(seqs, axis=0) if seqs else np.empty((0, 500, 6), dtype=np.float32)

# # -------- ç‹€æ…‹æª¢æŸ¥ç«¯é» --------
# @app.get("/")
# async def root():
#     return {
#         "status": "API is running",
#         "models_loaded": model_load_status,
#         "service": "Arch Detection API"
#     }

# @app.get("/health")
# async def health_check():
#     return {
#         "status": "healthy",
#         "models": model_load_status,
#         "timestamp": datetime.now().isoformat()
#     }

# @app.get("/debug/models")
# async def debug_models():
#     """æ¨¡å‹èª¿è©¦ä¿¡æ¯"""
#     model_info = {
#         "gait_model_loaded": model_load_status["gait_model"],
#         "arch_model_loaded": model_load_status["arch_model"],
#         "current_files": [f for f in os.listdir('.') if f.endswith(('.h5', '.keras', '.hdf5'))],
#         "timestamp": datetime.now().isoformat()
#     }
#     return model_info

# # -------- API Endpoint --------
# @app.post("/analyze_flatfoot/")
# async def analyze_flatfoot(file: UploadFile = File(...)):
#     """
#     å…¼å®¹ Swift çš„ç«¯é»åç¨±
#     """
#     try:
#         print(f"æ”¶åˆ°æª”æ¡ˆ: {file.filename}")
        
#         # è®€å– CSV
#         content = await file.read()
#         df = pd.read_csv(io.StringIO(content.decode("utf-8")))
#         print(f"æ•¸æ“šå½¢ç‹€: {df.shape}")
#         print(f"æ•¸æ“šæ¬„ä½: {df.columns.tolist()}")

#         # 1) HS/TO æª¢æ¸¬
#         df = detect_hs_to(df)

#         # 2) åˆ‡æ­¥ & è¦–çª—åŒ–
#         X = build_windows(df)
#         if len(X) == 0:
#             return JSONResponse(
#                 status_code=400, 
#                 content={"status": "error", "message": "ç„¡æ³•å½¢æˆæœ‰æ•ˆçš„ 5-step è¦–çª—"}
#             )

#         # 3) æ‰å¹³è¶³æ¨¡å‹æ¨è«–
#         if arch_model is None:
#             # ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
#             print("âš ï¸ Arch æ¨¡å‹æœªè¼‰å…¥ï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
#             p_flat = 0.75
#             diagnosis = "é«˜é¢¨éšª"
#         else:
#             try:
#                 probs = arch_model.predict(X, verbose=0)
#                 p_flat = float(probs[:,1].mean())
#                 diagnosis = "é«˜é¢¨éšª" if p_flat >= 0.6 else "æ­£å¸¸"
#                 print(f"æ¨¡å‹é æ¸¬: p_flat={p_flat}, diagnosis={diagnosis}")
#             except Exception as e:
#                 print(f"âŒ æ¨¡å‹é æ¸¬éŒ¯èª¤: {e}")
#                 p_flat = 0.75
#                 diagnosis = "é«˜é¢¨éšª"

#         # 4) å­˜å…¥è³‡æ–™åº«
#         conn = sqlite3.connect('gait_results.db')
#         c = conn.cursor()
#         c.execute("INSERT INTO arch_results VALUES (?,?,?,?,?,?)",
#                   (datetime.now().isoformat(), p_flat, diagnosis, 
#                    "current_user", file.filename, len(X)))
#         conn.commit()
#         conn.close()

#         # 5) å›å‚³çµæœ (å…¼å®¹ Swift æ ¼å¼)
#         result_data = {
#             "timestamp": datetime.now().isoformat(),
#             "probability": p_flat,
#             "diagnosis": diagnosis
#         }

#         return {
#             "status": "success",
#             "results": [result_data],
#             "analysis_info": {
#                 "file": file.filename,
#                 "windows_count": len(X),
#                 "model_used": model_load_status["arch_model"]
#             }
#         }

#     except Exception as e:
#         error_msg = f"åˆ†æéŒ¯èª¤: {str(e)}"
#         print(error_msg)
#         traceback.print_exc()
#         return JSONResponse(
#             status_code=500,
#             content={"status": "error", "message": error_msg}
#         )

# @app.get("/get_flatfoot_results/")
# async def get_flatfoot_results(user_id: str = "current_user", limit: int = 10):
#     """ç²å–æ­·å²çµæœ"""
#     try:
#         conn = sqlite3.connect('gait_results.db')
#         c = conn.cursor()
#         c.execute("SELECT timestamp, probability, diagnosis FROM arch_results WHERE user_id=? ORDER BY timestamp DESC LIMIT ?", 
#                   (user_id, limit))
        
#         results = [{
#             "timestamp": r[0], 
#             "probability": r[1],
#             "diagnosis": r[2]
#         } for r in c.fetchall()]
        
#         conn.close()
        
#         return {
#             "status": "success", 
#             "results": results
#         }
    
#     except Exception as e:
#         return JSONResponse(
#             status_code=500,
#             content={"status": "error", "message": str(e)}
#         )

# # --- å•Ÿå‹• ---
# if __name__ == "__main__":
#     port = int(os.environ.get("PORT", 8000))
#     print(f"å•Ÿå‹•æœå‹™åœ¨ç«¯å£ {port}")
#     uvicorn.run(app, host="0.0.0.0", port=port, workers=1, timeout_keep_alive=60)
